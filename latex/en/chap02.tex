\chapter{Proof of the \MWT}

\section{Every V-Cone is an H-Cone}

\begin{Def}[Coordinate Projection]
	Let $I$ be the identity matrix.  Then the matrix $I'$ formed by deleting some rows from $I$ is called a \textbf{coordinate-projection}.
\end{Def}

The proof rests on the following two lemmas:

\begin{Lemma}[Lifting a V-Cone]\label{vconelift}
	 Every V-Cone is a coordinate-projection of an H-Cone.
\end{Lemma}

\begin{Lemma}[Projecting an H-Cone]\label{hconeproject}
	 Every coordinate-projection of an H-Cone is an H-Cone.
\end{Lemma}

\begin{proof}
	Given \Cref{vconelift} and \Cref{hconeproject}, the proof follows simply.  Given a V-Cone, we use \nameref{vconelift} to get a description involving coordinate-projection of an H-Cone.  Then we can apply \nameref{hconeproject} in order to get an H-Cone.
\end{proof}

\begin{proof}[Proof of \nameref{vconelift}]
	We prove that every V-Cone is a coordinate-projection of an H-Cone, by giving an explicit formula.  Let ${\mU}$, and observe that
	\[ \cone(U) = \set{U\t \st \t \in \R^{\Udim},\, \t \geq \0} =
		\set{\xv \st (\exists \tv)\,\x = U\t,\, \t \geq \0} \]
	We will collect $\t$ and $\x$ on the left side of the inequality, treating $\t$ as a variable and expressing its contraints as linear inequalities, then project away the coordinates corresponding to $\t$.  The following expression takes one step:
	\begin{equation}\label{eq:tleqz}
		\t \geq \0 \Leftrightarrow -I\t \leq \0
	\end{equation}
	Using the equality: $a = 0 \Leftrightarrow a \leq 0 \land -a \leq 0$, and block matrix notation, we take the second step.
	\begin{equation}\label{eq:xeqt}
		\x = U\t \Leftrightarrow \x - U\t = \0 \Leftrightarrow
		\begin{pmatrix*}[r] I & -U \\ -I & U \end{pmatrix*} \xt \leq \0
	\end{equation}
	Comparing \eqref{eq:tleqz} and \eqref{eq:xeqt}, we define a matrix tranform:
  \begin{Transform}[V-Cone Lift]\label{vconelift_transform}
  \[\VLift(U) = \pmb \0 & -I \\ I & -U \\ -I & U \pme \]
  \end{Transform}
  So we define $A' = \VLift(U)$, then we can rewrite $\cone(U)$:
	\begin{equation*}
		\cone(U) = \set{ \xv \St A'\xt \leq \0}
	\end{equation*}
	Let $\Pi \in \set{0,1}^{d\times(d+\Udim)}$ be the identity matrix in $\R^{(d+\Udim)\times(d+\Udim)}$, but with the last $\Udim$-rows deleted.  Then $\Pi$ is a coordinate projection, and the above expression can be written:
	\begin{equation}\label{eq:vconelift}
		\cone(U) = \Pi\left(\set{ \y \in \R^{d+\Udim} \st A'\y \leq \0}\right)
	\end{equation}
	This is a coordinate projection of an H-Cone, and \nameref{vconelift} is shown.
\end{proof}

To prove \nameref{hconeproject}, we use two separate propositions.
\begin{Prop}[Projecting Null Columns]\label{proj_0_columns}
	Let $B\in\R^{m'\times(d+\Udim)}$, $B'$ be $B$ with the last $\Udim$ columns deleted, and $\Pi$ the identity matrix with the last $\Udim$ rows deleted (i.e. $B' = \Pi B$).  Furthermore, suppose that the last $\Udim$ columns of $B$ are $\0$.  Then
	\[ \Pi\left(\set{\y \in \R^{d+\Udim} \st B\y \leq \0}\right) =
		\set{\x\in\R^d\st B'\x\leq\0} \]
\end{Prop}

\begin{proof}
	Recall that $B\y \leq \0$ means that $(\forall i)\ip{B_i}{\y} \leq 0$.  Because the last $\Udim$ columns of $B$ are $\0$, any row $B_i$ of $B$ can be written $(B'_i,\0)$, with $\0 \in \R^\Udim$.  We can also rewrite $\y\in\R^{d+\Udim}$ as $(\x,\w)$ with $\x\in\R^d,\w\in\R^\Udim$, so that $\x = \Pi(\y)$.  Then
	\[ \ip{B}{\y} = \ip{(B'_i,\0)}{(\x,\w)} = \ip{B'_i}{\x} = \ip{B'_i}{\Pi(\y)} \]
	It follows that
	\[ \ip{B_i}{\y} \leq 0 \Leftrightarrow \ip{B'_i}{\Pi(\y)} \leq 0 \]
	Since $B_i$ is an arbitrary row of $B$, the proposition is shown.
\end{proof}

In order to use the above proposition, we need a matrix with columns which are $\0$.  The next proposition shows us how to obtain such a matrix from another, while maintaining certain properties.

\begin{Prop}[Fourier Motzkin Elimination for H-Cones]\label{fm_hcone}
	Let $\mB$, $1 \leq k \leq (d+p)$, and $\x = \sum_{i\neq k}x_i \e_i$.  Then there exists a matrix $\mC$ with the following properties:
	\begin{enumerate}
		\item Every row of $B'$ is a postive linear combination of rows of $B$.
		\item $m_2$ is finite.
		\item The $k$-th column of $B'$ is $\0$.
		\item \((\exists t)B(\x + t\e_k) \leq \0 \Leftrightarrow B'\x \leq \0\)
	\end{enumerate}
\end{Prop}

\begin{proof}
	Partition the rows of $B$ as follows:
	\begin{alignat*}{3}
		 & P &  & = i & \st & \Bik > 0 \\
		 & N &  & = j & \st & \Bjk < 0 \\
		 & Z &  & = l & \st & \Blk = 0
	\end{alignat*}
	Then let $B'$ be a matrix with rows of the following forms:
	\begin{alignat*}{3}
		 & C_l    &  & = B_l                 & \st & l \in Z          \\
		 & C_{ij} &  & = \Bik B_j - \Bjk B_i & \st & i \in P, j \in N
	\end{alignat*}
	\textit{1} and \textit{2} are clear.  \textit{3} is satisfied for rows indexed by $Z$ by definition  That it holds for the other rows, observe:
   \[\ip{C_{ij}}{\e_k} = \ip{\Bik B_j - \Bjk B_i}{\e_k} = \Bik \Bjk - \Bjk \Bik = 0\]
	The right direction of \textit{4} is shown in the following calculations.  Because $\Blk = 0$:
	\[ \ip{B_l}{\x+t\e_k} = \ip{B_l}{\x} + t\Blk = \ip{B_l}{\x} = \ip{C_l}{\x} \]
	So $\ip{B_l}{\x+t\e_k} \leq 0 \Rightarrow \ip{C_l}{\x} \leq 0$.  For rows indexed by $P,N$, because $\Bik \Bjk - \Bjk \Bik = 0$ we have:
	\[ \ip{\Bik B_j - \Bjk B_i}{\x + t\e_k} = \ip{\Bik B_j - \Bjk B_i}{\x} \]
	Because $\Bik$ and $-\Bjk$ are non-negative:
	\[ \ip{B_i}{\x+t\e_k} \leq 0,\; \ip{B_j}{\x+t\e_k} \leq 0 \Rightarrow
		\ip{\Bik B_j - \Bjk B_i}{\x + t\e_k} \leq 0\]
	Therefore $\ip{\Bik B_j - \Bjk B_i}{\x} \leq 0$, and the right implication is shown.

	Now suppose that $B'\x \leq \0$.  The task is to find a $t$ so that $B\x \leq \0$.  Because rows indexed by $Z$ have $\Blk = 0$, $B'(\x+t\e_k) \leq \0 \Rightarrow B\x \leq \0$.  So the task is to find a $t$ so that the inequality holds for rows indexed by $P$ and $N$.  Observe
	\begin{alignat*}{3}
		\faij & \quad & \ip{\Bik B_j - \Bjk B_i}{\x}    & \leq  \; 0                                & \Leftrightarrow \\
		\faij & \quad & \ip{\Bik B_j}{\x}               & \leq  \; \ip{\Bjk B_i}{\x}                & \Leftrightarrow \\
		\faij & \quad & \ip{B_i/\Bik}{\x}               & \leq  \; \ip{B_j/\Bjk}{\x}                & \Leftrightarrow \\
		      & \quad & \max_{i\in P} \ip{B_i/\Bik}{\x} & \leq  \; \min_{j\in N}  \ip{B_j/\Bjk}{\x} &
	\end{alignat*}
	Note that the third inequality changes directions because $\Bjk < 0$.  Now we choose $t$ to lie in this last interval, and show that we can use it to satisfy all of the constraints given by $ B$.  So, we have a $t$ such that
	\[ \max_{i\in P} \ip{B_i/\Bik}{\x} \leq t \leq \min_{j\in N} \ip{B_j/\Bjk}{\x} \]
	In particular,
  \[(\forall j\in N)\quad \ip{B_j/\Bjk}{\x} \geq t \Rightarrow \ip{B_j}{\x} - \Bjk t \leq 0\]
	Again, the inequality changes directions because $\Bjk < 0$.  Now consider a row $ B_j$ from $ B$:
	\[ \ip{B_j}{\x-t\e_k} =  B_j {\x} - \Bjk t \leq 0 \]
	Similarly,
  \[(\forall i\in P)\quad t \geq B_i/\Bik {\x} \Rightarrow 0 \geq B_i {\x} - \Bik t\]
	Now consider a row $ B_i$ from $ B$:
	\[ \ip{B_i}{\x-t\e_k} =  B_i {\x} - \Bik t \leq 0 \]
	So, we've demonstrated that $\x-t\e_k$ satisfies all the constraints from $B$, and the left implication is shown.  So \textit{4} holds.
\end{proof}

\begin{Remark}[Fourier Motzkin Matrix]\label{fm_matrix}
	 \nameref{fm_hcone} highlights the properties of the matrix $B'$.  Upon close inspection, we can create a Matrix $Y$ such that $B' = YB$, and every element of $Y$ is non-negative.  Create the following set of row vectors $Y$
	\begin{alignat*}{2}
		 & \e_l                  & \st & l \in Z          \\
		 & \Bik \e_j - \Bjk \e_i & \st & i\in P,\; j\in N
	\end{alignat*}
	Since the basis vectors simply select rows during matrix multiplication, it is clear that
	\[ B' = YB \]
\end{Remark}

\begin{proof}[Proof of \nameref{hconeproject}]
	Here we prove the case that the coordinate projection is onto the first $d$ of $d+p$ coordinates.  Let $\set{\y\in\R^{d+\Udim}:A'\y \leq \0}$ be the H-Cone we need to project, and $\Pi$ the coordinate-projection we need to apply (the identity matrix with the last p columns deleted).  For each $1 \leq k \leq p$ we can use \nameref{fm_hcone} in an incremental manner, starting with $A'$.
	\begin{align*}
		 & \text{let } B_0 := A'                                        \\
		 & \text{for } 1 \leq k \leq p                                  \\
		 & \quad \text{let } B_k :=
		\text{result of proposition 2 applied to $B_{k-1}$, $\e_{d+k}$} \\
		 & \text{endfor}                                                \\
		 & \text{return } B_p
	\end{align*}

	Consider the resulting $B$.  Property \textit{2} holds throughout, so $B$ is finite.  After each iteration, property \textit{3} holds for $k$, so the $k$-th column is $\0$.  Since each iteration only results from non-negative combinations of the result of the previous iteration (property \textit{1}), once a column is $\0$ it remains so.  Therefore, at the end of the process, the last $p$ columns of $B$ are all $\0$.  Then, by \nameref{proj_0_columns}, we can apply $\Pi$ to $B$ by simply deleting the last $p$ columns of $B$.  Denote this resulting matrix $A$.  We still need to check that
	\begin{equation}\label{eq:V2equal}
		\Pi\set{\y\in\R^{d+\Udim}\st A'\y\leq\0} = \set{\x\in\R^{d}\st A\x\leq\0}
	\end{equation}
	This follows from the following:
	\begin{align}
		A'\y & \leq \0 \Rightarrow A(\Pi(\y)) \leq \0 \label{V2seteqright}                                                           \\
		A\x  & \leq \0 \Rightarrow (\exists t_1)\dots(\exists t_p) A'(\x+t_1\e_{d+1}+\cdots+t_p\e_{d+p}) \leq \0 \label{V2seteqleft}
	\end{align}
	The key observation of this verification utilizes property \textit{4} of \nameref{fm_hcone}:
	\[ (\exists t)B(\x + t\e_k) \leq \0 \Leftrightarrow B'\x \leq \0 \]
	In what follows, let $\x = \sum_{1 \leq j \leq d}x_j\e_j$.  The above property is applied sequentially to the sets $B_k$ as follows:
	\begin{alignat*}{2}
		(\exists t_p)(\exists t_{p-1})\dots(\exists t_1)                & \quad
		B_0(\x + t_1\e_{p} + t_2\e_{p-1} + \dots + t_p\e_{d}) \leq \0\; & \Leftrightarrow                                                 \\
		(\exists t_p)\dots(\exists t_2)                                 & \quad
		B_1(\x + t_2\e_{d+2} + \dots + t_p\e_{d+p})
		\leq \0                                                         & \Leftrightarrow                                                 \\
		\vdots \hspace{1.3em}                                           & \hspace{5em}\vdots                       & \vdots\hspace{0.4em} \\
		(\exists t_p)                                                   & \quad B_{p-1}(\x + t_p\e_{d+p})  \leq \0 & \Leftrightarrow      \\
		                                                                & \quad B_{p}\x  \leq \0                   &
	\end{alignat*}
	Because $A' = B_0$, and $A$ is $B_p$ with the last $p$ columns deleted, \eqref{V2seteqright} and \eqref{V2seteqleft} hold, therefore \eqref{eq:V2equal} holds, and the proof of \nameref{hconeproject} is complete, and we've shown that a coordinate projection of an H-Cone is again an H-Cone.
\end{proof}

With \nameref{vconelift} and \nameref{hconeproject} proven, we are now certain that any V-Cone is also an H-Cone.

\section{Every H-Cone is a V-Cone}

\begin{Def}[Coordinate Hyperplane]
	A set of the form
	\[ \set{\x \in \R^{d+\Adim} \st \ip{\x}{\e_k} = 0} =
		\set{\x \in \R^{d+\Adim} \st x_k = 0}
	\]
	is called a \em{coordinate-hyperplane}.
\end{Def}

This is how coordinate hyperplanes will be used.  We consider a V-Cone intersected with some coordinate hyperplanes, and write it in the following way:
\begin{equation}\label{eq:coneintform1}
	\set{\xv \St (\exists \t \geq 0) \xz = U'\t}
\end{equation}
If we suppose that $U' \subset \R^{d+\Adim}$, and $\Pi$ is the identity matrix with the last $\Adim$ rows deleted, then this is just a convenient way of writing:
\begin{equation}\label{eq:coneintform2}
	\Pi\big(\cone(U') \cap \set{x_{d+1} = 0}
	\cap \dots \cap \set{x_{d+\Adim} = 0}\big)
\end{equation}
The proof rests on the following three propostions:
\begin{Lemma}[Lifting an H-Cone]\label{hconelift}
  Every H-Cone is a coordinate-projection of a V-Cone intersected with some coordinate hyperplanes.
\end{Lemma}
\begin{Lemma}[Intersecting a V-Cone]\label{vconeintersect}
  Every V-Cone intersected with a coordinate-hyperplane is a V-Cone.
\end{Lemma}
\begin{Lemma}[Projecting a V-Cone]\label{vconeproject}
  Every coordinate-projection of a V-Cone is an V-Cone.
\end{Lemma}

\begin{proof}
	Given \cref{hconelift}, \cref{vconeintersect}, and \cref{vconeproject}, the proof follows simply.  Given an H-Cone, we use \nameref{hconelift} to get a description involving the coordinate-projection of a V-Cone intersected with some coordinate-hyperplanes.  We apply \nameref{vconeintersect} as many times as necessary to elimintate the intersections, then we can apply \nameref{vconeproject} in order to get a V-Cone.
\end{proof}

\begin{proof}[Proof of \nameref{hconelift}]
	Let $\mA$, we now show that the H-Cone
	\[\set{\xv \st A\x \leq \0}\]
	can be written as the projection of a V-Cone intersected with some hyperplanes.  We use the following transform.
  \begin{Transform}[H-Cone Lift]\label{hconelift_transform}
  \[\HLift(A) = \pmb \0 & I & -I \\ I & A & -A \pme \]
  \end{Transform}
  Define 
  \[U' = \HLift(A) =  \set{\zei, \eAj, \neAj, 1 \leq j \leq d,\, 1 \leq i \leq m}\]
	We then claim:
	\begin{equation}\label{eq:hliftform}
		\set{\xv \st A\x \leq \0} = \set{\xv \St (\exists \t \geq 0) \xz = U'\t}
	\end{equation}
	First, considering \eqref{eq:coneintform1} and \eqref{eq:coneintform2}, observe that this is a coordinate-projection of a V-Cone intersected with some coordinate-hyperplanes.
	Next, we note that
	\[ \xAx = \jsum x_j \eAj \]
	We can write this as a sum with all positive coefficients if we split up the $x_j$ as follows:
	\[
		\xjp = \begin{cases} x_j & x_j \geq 0 \\ 0 & x_j < 0 \end{cases} \quad\quad\quad
		\xjm = \begin{cases} 0 & x_j \geq 0 \\ -x_j & x_j < 0 \end{cases}
	\]
	Then we have
	\begin{equation} \label{eq:xAx}
		\xAx = \jsum \xjp \eAj + \jsum \xjm \neAj
	\end{equation}
	where $\xjp, \xjm \geq 0$.  Also observe that
	\[ A\x \leq \0 \Leftrightarrow (\exists \w \geq \0) \st A\x + \w = \0 \]
	This can also be written
	\begin{equation} \label{eq:Axz}
		A\x \leq \0 \Leftrightarrow (\exists \w \geq \0) \st \xAx + \zw = \xz
	\end{equation}
	\eqref{eq:xAx} and \eqref{eq:Axz} together show
	\[ A\x \leq \0 \Rightarrow (\exists \t \geq 0) \xz = U'\t \]
	Conversely, suppose
	\[ (\exists \t \geq 0) \xz = U'\t \]
	We would like to show that $A\x \leq \0$.  Let $\xjp,\xjm,w_i$ take the values of $\t$ that are coefficients of $\eAj$, $\neAj$, and $\zei$ respectively, and denote $x_j = \xjp - \xjm$.  Then we have
	\begin{align*}
		\xz & = \jsum \xjp \eAj + \jsum \xjm \neAj + \isum w_i\zei \\
		    & = \jsum x_j \eAj + \isum w_i\zei                     \\
		    & = \xAx + \zw
	\end{align*}
	where $\w \geq \0$.  By \eqref{eq:Axz} we have $A\x \leq \0$.  So \eqref{eq:hliftform} holds.
\end{proof}

The proof of \nameref{vconeintersect} relies upon the following proposition.
\begin{Prop}[Fourier Motzkin Elimination for V-Cones]\label{fm_vcone}
	Let $Y \in \R^{(d+m)\times n_1}$, $1 \leq k \leq m$, and $\x$ satisfy $x_k = 0$.  Then there exists a matrix $Y' \in \R^{(d+m)\times n_2}$ with the following properties:
	\begin{enumerate}
		\item Every column of $Y'$ is a postive linear combination of columns of $Y$.
		\item $n_2$ is finite.
		\item The $k$-th row of $Y'$ is $\0$.
		\item \((\exists \t\geq\0)\x = Y\t \Leftrightarrow (\exists \t' \geq \0)\x = Y'\t'\)
	\end{enumerate}
\end{Prop}

\begin{proof}
	We partition the columns of $ Y$:
	\begin{alignat*}{3}
		 & P &  & = i \; & \st & \Yi > 0 \\
		 & N &  & = j \; & \st & \Yj < 0 \\
		 & Z &  & = l \; & \st & \Yl = 0
	\end{alignat*}
	We then define $ Y'$:
	\[  Y' = \set{ Y^l \st l \in Z} \cup
		\set{\Yi Y^j - \Yj Y^i \st i \in P,\, j\in N} \]
	\textit{1} and \textit{2} are clear.  \textit{3} can be seen from:
	\begin{align}
		\ip{Y'^l}{\e^k}    & = 0 \nonumber                                                                \\
		\ip{Y'^{ij}}{\e^k} & = \ip{\Yi Y^j - \Yj Y^i}{\e^k} = \Yi \Yj - \Yj \Yi = 0 \label{eq:hdropZrows}
	\end{align}

	Before moving on to the proof, we first note how we may write our vectors.
	\[  Y\t = \Zsum t_k  Y^k + \Psum t_i  Y^i + \Nsum t_j  Y^j \]
	\[  Y'\t = \Zsum t_k  Y^k + \NPsum t_{ij} (\Yi Y^j - \Yj Y^i) \]
	Then, by \nameref{cone_closure} (cone closure), to show that the proposition is true, we need only show that, given any $t_i, t_j \geq 0$ ($t_{ij} \geq 0)$, there exists $t_{ij} \geq 0$ ($t_i, t_j \geq 0$) such that
	\begin{equation} \label{eq:coneEq}
		\Psum t_i  Y^i + \Nsum t_j  Y^j = \NPsum t_{ij} (\Yi Y^j - \Yj Y^i)
	\end{equation}

	\newcommand{\coneEqSat}{\quad\mathrm{\;such\; that\; \eqref{eq:coneEq}\; holds}}
	\begin{Prop}[Sum Mixture]\label{sum_mixture}
		Suppose that
		\[ \Psum t_i  Y^i_{d+1} + \Nsum t_j  Y^j_{d+1} = 0\quad\quad \Yj < 0 < \Yi \]
		Then the following holds
		\begin{alignat*}{2}
			(t_i, t_j \geq 0) & \Rightarrow (\exists t_{ij} \geq 0)   &  & \coneEqSat \\
			(t_{ij} \geq 0)   & \Rightarrow (\exists t_i, t_j \geq 0) &  & \coneEqSat
		\end{alignat*}
	\end{Prop}

	\begin{proof}[Proof of \cref{sum_mixture}]
		First note that if all $t_i = 0,t_j = 0$, then choosing $t_{ij} = 0$ satisfies \eqref{eq:coneEq}, likewise if all $t_{ij} = 0$, then $t_i = 0, t_j = 0$ satisfies \eqref{eq:coneEq}.  So suppose that some $t_i \neq 0, t_j \neq 0, t_{ij} \neq 0$.

		The right hand side of \eqref{eq:coneEq} can be written
		\[ \Nsum \left(\Psum t_{ij}\Yi\right) Y^j +
			\Psum \left(-\Nsum t_{ij}\Yj\right) Y^i \]
		This means, given $t_{ij} \geq 0$, we can choose $t_j = \Psum t_{ij}\Yi$, and $t_i = -\Nsum t_{ij}\Yj$, both of which are greater than $0$.

		Now suppose we have been given $t_i \geq 0, t_j \geq 0$.  First observe:
		\[ 0 = \Psum t_i\Yi + \Nsum t_j\Yj \Rightarrow \Psum t_i\Yi = -\Nsum t_j\Yj\]
		Denote the value in this equality as $\sigma$, and note that $\sigma > 0$.  Then
		\begin{alignat*}{3}
			\Psum t_i Y^i & = & \frac{-\Nsum t_j \Yj}{\sigma}\Psum t_i Y^i & =
			\NPsum -\frac{t_i t_j}{\sigma}\Yj Y^i                              \\
			\Nsum t_j Y^j & = & \frac{\Psum t_i \Yi}{\sigma}\Nsum t_j Y^j  & =
			\NPsum \frac{t_i t_j}{\sigma}\Yi Y^j
		\end{alignat*}
		Combining these results, we have
		\[ \Psum t_i Y^i + \Nsum t_j Y^j = \NPsum \frac{t_i t_j}{\sigma}(\Yi Y^j - \Yj Y^i) \]
	\end{proof}
	Finally, we can conclude that, given $\t \geq \0$, if $Y\t$ has a $0$ in the final coordinate, then we can write it as $ Y'\t'$ where $\t' \geq \0$, and any non-negative linear combination of vectors from $Y'$ can be written as a non-negative linear combination of vetors from $Y$, and will necessarily have the $k$-th coordinate be $0$ by property \textit{3}.  So property \textit{4} holds.
\end{proof}

\begin{proof}[Proof of \nameref{vconeintersect}]
	In \nameref{fm_vcone}, the assumption that $x_k = 0$ in property \textit{4} creates the set $\cone(Y) \cap \set{\x \st x_k = 0}$.  This set, by property \textit{4}, is $\cone(Y')$.
\end{proof}

\begin{proof}[Proof of \nameref{vconeproject}]
	We shall prove that the coordinate-projection of a V-Cone is again a V-Cone.  Let $\Pi$ be the relevant projection, then we have:
	\[ \Pi\set{U\t \st \t \geq \0} = \set{\Pi(U\t) \st \t \geq \0} =
		\set{(\Pi U)\t \st \t \geq \0} \]
	The last equality follows from associativity of matrix multiplication.  Therefore,
	\[ \Pi\big(\cone(U)\big) = \cone\big(\Pi U\big) \]
\end{proof}

Having shown that H-Cones are V-Cones, the proof of the {\MWT} for cones is complete.

\section{Reducing Polyhedra to Cones}

\begin{Def}[Hyperplane]
	Let $\y \in \R^d$, $c \in \R$.  Then a set of the form
	\[ \set{\xv \st \ip{\y}{\x} = c} \]
	is called a \em{hyperplane}.
\end{Def}

\subsection{H-Polyhedra $\leftrightarrow$ H-Cones}

\newcommand{\hpxz}{\set{\x\st x_0 = 1}}
\begin{Prop}
	Every H-Polyhedron can be written as an H-Cone intersected with the set $\hpxz$, and any H-Cone intersected with the set $\hpxz$ is an H-Polyhedron.
\end{Prop}

\begin{proof}
	We begin by re-writing the expression:
	\[	A\x \leq \b \Leftrightarrow -\b + A\x \leq \0 \Leftrightarrow
		\big[-\b|A\big]\onex \leq \0 \]
	Note that
	\[\set{\x\St\big[-\b|A\big]\onex\leq\0} = \LHC \cap \hpxz \]
	It follows that
	\[ \HP{A}{\b} = \LHC \cap \hpxz \]
\end{proof}

\subsection{V-Polyhedra $\leftrightarrow$ V-Cone}

\begin{Prop}[V-Polyhedron $\to$ V-Cone]
	\[ \VP{U}{V} = \cone\pmb \0 & \1 \\ U & V \pme \cap \hpxz \]
\end{Prop}

\begin{proof}
	For the value $1$ to appear in the first coordinate, a convex combination of the vectors from $(\vec{1}, V)$ must be taken.  After that, any non-negative combination of $(\0,U)$ added to this vector won't affect the $1$ in the first coordinate.
\end{proof}

This shows that a V-Polyhedron may be written as an intersection of a V-Cone and the hyperplane $\hpxz$.  It is more difficult to show that, given a V-Cone, that you can intersect it with the hyperplane $\hpxz$ and get a V-Polyhedron out of it.

\begin{Prop}[V-Cone $\to$ V-Polyhedron]\label{vcone_to_vpoly}
	Let $\Pi$ be the identity matrix with the first row deleted.  Then, for any set $C_U = \cone(U)$ there are sets $W$ and $V$ such that
	\[ \cone(V) \cap \hpxz = \VP{W}{V} \]
\end{Prop}

\begin{proof}
	We partition $U$ into the sets:
	\begin{alignat*}{3}
		 & P &  & = i & \st & \Uiz > 0 \\
		 & N &  & = j & \st & \Ujz < 0 \\
		 & Z &  & = l & \st & \Ulz = 0
	\end{alignat*}
	And define two new sets:
	\begin{align*}
		W   & = \set{U^l \st l \in Z} \cup \set{\Uiz U^j - \Ujz U^i \st i\in P,\, j\in N} \\
		V\; & = \set{U^i/\Uiz \st i \in P}
	\end{align*}
	Then I claim that
	\[ C_U = \VP{W}{V} \]
	Say $\x \in\cone(W)$, and $\y\in\conv(V)$.  Then $\x$ can be written
	\begin{align*}
		\x & = \sum_{l\in Z}t_l U^l + \NPsum t_{ij}(\Uiz U^j - \Ujz U^i)      \\
		   & = \sum_{l\in Z}t_l U^l + \Nsum \left(\Psum t_{ij}\Uiz\right) U^j
		+ \Psum \left(\Nsum -t_{ij}\Ujz\right) U^i
	\end{align*}
	So $\x \in C_U$.  Furthermore,
	\[ \ip{\e_0}{\x} = \sum_{l\in Z}t_l \Ulz + \NPsum t_{ij}(\Uiz \Ujz - \Ujz \Uiz) = 0\]
	So $x_0 = 0$.  Similarly, $\y$ can be written:
	\[ \y = \Psum \lambda_i U^i/\Uiz,\quad\Psum\lambda_i = 1 \]
	So $\y \in C_U$.  Furthermore,
	\[ \ip{\e_0}{\y} = \Psum \lambda_i \Uiz/\Uiz = \Psum \lambda_i  = 1\]
	So $y_0 = 1$ and $x_0 + y_0 = 1$.  It follows that $\x + \y \in C_U$.

	Next, suppose that $\z \in C_U$, then $\z$ can be written
	\[ \z = \Zsum t_l U^l + \Psum t_i U^i + \Nsum t_j U^j \]
	It will be convenient to use shorter notation for these sums.  Define the following:
	\begin{alignat*}{3}
		\bsigma_Z & = \Zsum t_l U^l, \quad &  & \sigma_l \, & = & \, \Zsum t_l \Ulz \;= 0 \\
		\bsigma_P & = \Psum t_i U^i, \quad &  & \sigma_i \, & = & \, \Psum t_i \Uiz       \\
		\bsigma_N & = \Nsum t_j U^j, \quad &  & \sigma_j \, & = & \, \Nsum t_j \Ujz
	\end{alignat*}
	Then it holds that
	\[ \ip{\e_0}{\z} = \sigma_l + \sigma_i + \sigma_j = \sigma_i + \sigma_j = 1
		\quad\Rightarrow\quad -\sigma_j/\sigma_i = 1 - 1/\sigma_i \]
	\[ \bsigma_P = \bsigma_P/\sigma_i + (1-1/\sigma_i)\bsigma_P
		= \bsigma_P/\sigma_i - (\sigma_j/\sigma_i)\bsigma_P \]
	Using the new notation, we can rewrite $\z$:
	\[ \z = \bsigma_Z + \bsigma_P + \bsigma_N
		= \bsigma_Z + \frac{\bsigma_P}{\sigma_i} - \frac{\sigma_j}{\sigma_i}\bsigma_P
		+ \frac{\sigma_i}{\sigma_i}\bsigma_N
		= \bsigma_Z + \frac{\bsigma_P}{\sigma_i} +
		\frac{\sigma_i\bsigma_N - \sigma_j\bsigma_P}{\sigma_i}
	\]
	Using \Nameref{cone_closure}, we need only show that
	\begin{enumerate}
		\item $\bsigma_Z \in \cone(W)$
		\item $(\sigma_i\bsigma_N - \sigma_j\bsigma_P) \in \cone(W)$
		\item $\bsigma_P/\sigma_i \in \conv(V)$
	\end{enumerate}
	Since each $U^l : l \in Z$ is in $C_V$, (1) holds.  We also have:
	\[ \sigma_i\bsigma_N - \sigma_j\bsigma_P =
		\Psum t_i \Nsum t_j \Uiz U^j - \Nsum t_j \Psum t_i \Ujz U^i =
		\NPsum t_i t_j(\Uiz U^j - \Ujz U^i) \]
	So (2) holds.  Finally,
	\[ \bsigma_P/\sigma_i = \Psum t_i U^i / \sigma_i = \Psum (t_i \Uiz/\sigma_i)(U^i/\Uiz) \]
	Since $\Psum (t_i \Uiz/\sigma_i) = \sigma_i / \sigma_i = 1$, it follows that $\bsigma_P / \sigma_i \in \conv(V)$.
\end{proof}

\section{Picture of the Proof}
Here we show a diagram that represent the proof of the {\MWT}.
\definecolor{mygrey}{rgb}{.1,.1,.1}
\newcommand{\FIGstep}{2}
\newcommand{\FIGge}{8}
\newcommand{\FIGgd}{\numexpr \FIGge-\FIGstep}
\newcommand{\FIGgc}{\numexpr \FIGgd-\FIGstep}
\newcommand{\FIGgb}{\numexpr \FIGgc-\FIGstep}
\newcommand{\FIGga}{\numexpr \FIGgb-\FIGstep}
\newcommand{\ptovcolor}{violet}
\newcommand{\liftcolor}{blue}
\newcommand{\dropcolor}{red}
\newcommand{\VDropdesc}{$\Pi\circ\bigcap$}
\newcommand{\HDropdesc}{$\Pi$}
\newcommand{\HPdesc}{\HP{A}{\b}}
\newcommand{\HPidesc}{\LHC}
\newcommand{\HCdesc}{\HC{A}}
\newcommand{\HCpdesc}{\pmb \0 & -I \\ I & -U \\ -I & U \pme \x \leq \0}
\newcommand{\VPdesc}{\VP{U}{V}}
%\newcommand{\VPidesc}{\cone\{\smallstack{\vec{0}}{U}\cup\smallstack{\vec{1}}{V}\}}
\newcommand{\VPidesc}{\cone\pmb\vec{0}&\vec{1}\\{U}&{V}\pme}
\newcommand{\VCdesc}{\cone(U)}
\newcommand{\VCpdesc}{\cone \pmb 0 & I & -I\\ I & A & -A\pme}
\begin{figure}[H]
	\begin{centering}
		\begin{tikzpicture}[>=triangle 45]
			\node (HP)  at (\FIGgd,\FIGge) {\framebox{$\HPdesc$}};
			\node (HPi) at (\FIGga,\FIGge) {\framebox{$\HPidesc$}};
			\node (HC)  at (\FIGga,\FIGgc) {\framebox{$\HCdesc$}};
			\node (HCp) at (\FIGgc,\FIGgb) {\framebox{$\HCpdesc$}};
			%
			\node (VP)  at (\FIGgb,\FIGga) {\framebox{$\VPdesc$}};
			\node (VPi) at (\FIGge,\FIGga) {\framebox{$\VPidesc$}};
			\node (VC)  at (\FIGge,\FIGgc) {\framebox{$\VCdesc$}};
			\node (VCp) at (\FIGgc,\FIGgd) {\framebox{$\VCpdesc$}};
			\draw[<->,color=\ptovcolor] (HP) to node[below]{lift} node[above]{\HDropdesc} (HPi);
			\draw[<->,color=\ptovcolor] (VP) to node[above]{lift} node[below]{\VDropdesc} (VPi);
			\draw[-,dashed,color=mygrey]  (HPi) to node[rotate=90,above]{(relabel)} (HC);
			\draw[-,dashed,color=mygrey]  (VPi) to node[rotate=90,below]{(relabel)} (VC);
			\draw[->,color=\liftcolor,bend left] (HC)  to node[above left]{lift} (VCp);
			\draw[->,color=\dropcolor,bend left] (VCp) to node[above right]{\VDropdesc} (VC);
			\draw[->,color=\liftcolor,bend left] (VC)  to node[below right]{lift} (HCp);
			\draw[->,color=\dropcolor,bend left] (HCp) to node[below left]{\HDropdesc} (HC);
			%HP <-> HPi
			%VP <-> VPi
			%HPi -  HC
			%VPi -  VC
			%HC  -> VCp
			%VC  -> HCi
			%VCp -> VC
			%HCp -> HC
			%
			%HPi  <-> HP
			%|
			%| ____VCp___
			%HC_        _VC
			%   \__HCp_/ |
			%            |
			%   VP <->  VPi
		\end{tikzpicture}
		\caption{Diagram of the proof $P_H \leftrightarrow P_V$}
		\label{fig:h_to_v}
	\end{centering}
\end{figure}

Figure \ref{fig:h_to_v} shows the flow from an H-Polyhedron to a V-Polyhedron and back.  There are \textcolor{\ptovcolor}{arrows} for transformations back and forth from polyhedra to cones, \textcolor{\liftcolor}{arrows} to show the transformation between cones and intermediate representation, and \textcolor{\dropcolor}{arrows} to show where Fourier Motzkin elimination is applied to reduce these intermediate represenations to standard cones.  V-Cones are \textcolor{\liftcolor}{lifted} to H-Cones which need to be \textcolor{\dropcolor}{projected (\HDropdesc)}, and H-Cones are \textcolor{\liftcolor}{lifted} to V-Cones which need to be \textcolor{\dropcolor}{intersected and projected (\VDropdesc)}.
