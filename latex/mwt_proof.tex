%mwt_proof.tex

\input{proof_diagram}
\subsection{Overview}
The proof shall proceed by first considering an H-Polyhedron $\PH$, and constructing from it a V-Polyhedron $\PV$ which represents the same set of points, then starting with a V-Polyhedron $\PV$ and constructing an H-Polyhedron $\PH$.  The high-level steps are almost identical, and is illustrated in Figure \ref{fig:proof}.

First, $\PH$ will be relaxed to a cone $\CH$.  While technically unnecessary, in the steps that follow it is convenient to have a cone, as opposed to a more general polyhedron.  $\CH$ is then immediately lifted to a higher dimension so that it can be directly represented as a V-Cone $\CV$ \todo{have we defined V-Cone?}.  It is at this point that the ``real work'' must be done (which is why this arrow is colored red).  This step requires intersecting the V-Cone with a number of hyperplanes, and requires a process which is dual to the so-called ``\FME.''  At this point, a simple observation will allow us to restrict $\CV$ to get us to $\PV$, completing this direction of the proof.  Note that this restriction is the opposite of the relaxation which occurs at the beginning of this direction of the proof, as the colors of the diagram reflect.

For the other direction, the exact same steps are taken, however the relaxing and lifting that occur are designed to convert the V-Polyhedron into a V-Cone and H-Cone, instead of the other way around$^1$.  Also, the full fledged ``\FME'' shall take place, this time because we need to project an H-Cone down a number of dimensions.

The transformation which go from $V \to H$ and $H \to V$ representations in the proof seem like a bit of trickery, but in earnest these come from the field of Linear Programming.  For more information on these types of transformations, and a more systematic treatment of them, see \todo{that book by Matusek...}, for instance.

\medskip
Finally, before we get started, I'd like to mention that Ziegler provides the questions:
\begin{itemize}
  \item ``Is a polyhedron intersected with a hyperplane also a polyhedron?''
  \item ``Is the projection of a polyhedron also a polyhedron?''
\end{itemize}
as examples of the utility of the two different representations.  The answer to the first question is clear for H-Polyhedra, this is merely adding another constraint to the system, while it is not so clear for a V-Polyhedra (it seems as though you must somehow ``solve'' something to prove this...)  Similarly, the second question is clear for V-Polyhedra, you simply take the vectors that you already have and forget about some of the coordinates, while for H-Polyhedra it again seems like some system needs to somehow be solved in order to prove this statement.  Before you go and try to prove it yourself, know that the ``solving'' of these problems is essentially \FME, and is the bulk of the work in the proof that follows.

\subsection{H-Polyhedra $\to$ V-Polyhedra}
\paragraph{Overview}
As Figure \ref{fig:proof} indicates, the proof in this direction will generally be of the following form:
  \[ \PH \to \CH \to \CVp \to \CV \to \PV \]
It should then be of no surprise that the actual proof is essentially just elucidating this diagram.

\subsubsection{Relax: $\PH \to \CH$} 
This is a straightforward step.  Let $\PH = \{x : A\x \leq \b\}$ for some $A$ and $\b$.  To achieve the form of a cone, the right hand side of the inequality needs to be $0$.  In order to do this, we prepend $\b$ to the matrix $A$, and introduce a new variable as follows:
  \[ A\x \leq \b \to [\b|A] \xx \leq 0 \]
Observe that this is in fact a relaxation to an H-Cone.  The restriction back to the original H-Polyhedron is to intersect the H-Cone with the hyperplane $\{\x : x_0 = 1\}$, that is:
  \[ \PH = \left\{ [\b|A] \xx \leq 0 \right\} \cap \{ \x : x_0 = 1 \} \]
For now, we deal with the relaxed cone $\CH$ and do this restriction as the last step in the proof of this direction.  In what follows, $A' = [\b|A]$ and $\x' = \xx$.  This notation will simplify the expressions that follow.

\subsubsection{Lift: $\CH \to \CVp$}
The task is to \textit{somehow} go from dealing with halfspaces to dealing with rays.  This step is deceptively ``easy,'' in that it requires a good idea.  Let $A^i$ denote the $i$-th column of $A$.  Observe that $A\x = \sum_i A^i\cdot x_i$.  The significance of this is that matrix multiplication can be considered in two fundamentally different ways, as either: a number of dot products $\dotproduct{\a_i}{\x}$, or as a linear combination of column vectors $\sum_i A^i\cdot x_i$.  This important difference is key to representing the inequality above as a cone.  Suppose that $A \in \R^{m\times n}$, i.e. that $A$ as $m$ rows, and consider the vector $x_i\cdot\smallstack{\e_i}{A^i} \in \R^{n + m}$.  Here, the first $n$ rows keep track of the \textit{value} and \textit{position} of the contribution of $x_i$ (a scalar) to the vector $\x$, while the bottom $m$ rows correspond to the contribution of $x_i$ to the \textit{sum} $\sum_i A^i\cdot x_i$.

Let $\pi_{\x} : \R^{n+m} \to \R^{n}$ be a projection to the first $n$ coordinates, and $\pi^{\x} : \R^{n+m} \to \R^{m}$ a projection to the last $m$ coordinates.  Now, consider the sum 
  \[ \sum\nolimits_i x_i \stack{\e_i}{A^i} = \stack{\x}{A\x} \]
This equality follows from the discussion that precedes it, and it is quite significant, mostly because:
  \[ \pi_{\x} \stack{\x}{A\x}\ = \x,\quad \pi^{\x} \stack{\x}{A\x}\ = A\x \]
\todo{I think that switching the notation of ``projection to'' and ``projection from'' would be in order}
Without further adieu, consider the cone:
  \[ \mathcal{C}_0 = \cone\left(\left\{\pm\stack{\e_i}{A^i}\right\}\right) \]
What are the members of this cone?  Say $\smallstack{\x}{\z} \in \mathcal{C}_0$, then this vector must be a positive linear combination of its generators \todo{define generators}.  In other words:
  \[ \exists\, t^+_i, t^-_i \geq 0 \left| \stack{\x}{\z} = 
       \sum\nolimits_i t^+_i \cdot\stack{\e_i}{A^i} + 
                       t^-_i \cdot{-\!\!\stack{\e_i}{A^i}} \right. =
       \sum\nolimits_i (t^+_i - t^-_i) \cdot\stack{\e_i}{A^i}
   \]
Letting $t_i = (t^+_i - t^-_i)$ in the above equations, and noting that $t_i$ can range over all of $\R$, we get:
  \[ \exists t_i \in \R \left| \stack{\x}{\z} = \sum\nolimits_i t_i \cdot\stack{\e_i}{A^i} \right.
       \Rightarrow \z = A\x \]
To recap what has been accomplished, we have created a V-Cone, in which the first $n$ coordinates keep track of some values corresponding to a vector we've been calling $\x$, and the final $m$ coordinates keep track of the result of the multiplication $A\x$.  This V-Cone becomes powerful when we fix $\z$, that is, taking the V-Cone's intersection with a set of the form $\{\smallstack{\x}{\z} \suchthat \z = \b\}$ for some carefully chosen vector $\b$.  Then, we take a projection of this new set formed by intersection, and recover useful values of $\x$, that is:
  \[ \pi_{\x}\left(\mathcal{C}_0 \cap 
             \left\{\stack{\x}{\z} \bigg|\; \z = \b \right\}\right) =
     \left\{\x \suchthat A\x = \b\right\} 
  \]
In this way, we can recover the solutions to the equation $A\x = \b$.  As previously mentioned, the projection of a V-Cone is easy to deal with, just restrict the generators to the desired coordinates, but the intersection is a bit trickier to deal with, and is the subject of the next part of the proof.  There is one more loose end to tie up before we go on.

As of right now, we have an alleged way to get the solutions of $A\x = \b$ from a V-Cone, but what we really need are the solutions to $A\x \leq \b$.  There is a quick and dirty way to get this from $\mathcal{C}_0$, through introducing what are known in linear programming circles as \textit{slack variables.}  This is just a form of relaxation.

Suppose that you have an $\x$ such that $A\x \leq \b$, and let $\w = \b - A\x$.  This $\w$ can be thought of as \textit{slack}, and is the key to getting from $\mathcal{C}_0$ to $\CVp$.  The key property of this slack is $0 \leq \w$, so $\w$ can be written as
  \[ \w = \sum\nolimits_j w_j\cdot\e_j 
          \Rightarrow \exists\,w_j \geq 0 \;\big|\; \w = \sum\nolimits_j w_j\cdot\e_j \]
Now, we add these bases vectors $\e_j$ to the generators of $\mathcal{C}_0$ to create $\CVp$:
  \[ \CVp = \cone\left(\left\{\pm\stack{\e_i}{A^i}\right\} \cup 
                 \left\{\stack{\vec{0}}{\e_j}\right\}\right) 
  \]
As before, we fix the last $m$ coordinates, carefully choosing our $\b$ to be $\vec{0}$, and again projecting to the coordinates that interest us:
  \[ \pi_{\x} \left( \CVp \cap \left\{\stack{\x}{\z} \bigg|\; \z = \vec{0}\right\} \right) = 
               \{\x \suchthat A\x \leq \vec{0}\}
  \]

\subsubsection{Drop: $\CVp \to \CH$}
Now we turn to intersecting $\CVp$ with $\left\{\smallstack{\x}{\z} |\, \z = \vec{0}\right\}$.

\subsection{V-Polyhedra $\to$ H-Polyhedra}
% by arrow

